# Other_competitions
Examples of my activities from different competitions

# Fake news recognition (Модель для распознование фальшивых новостей)

## Итоги работы

Целью задания была разработка модели, которая будет способна различать заголовки реальных и выдуманных новостей.   
Для оценки финального решения используется метрика F1 score. Также оценивается чистота кода, оформление и понятность исследования.  
Для обучения модели были использованы данные из файла train.tsv. В файле находится таблица, состоящая из двух колонок и 5758 строк. Количество уникальных слов — 20701. В колонке «title» записан заголовок новости. В колонке «is_fake» содержатся метки: 0 – новость реальная; 1 – новость выдуманная. Файл test.tsv, на котором предстоит осуществлять предсказание, аналогичен по количеству колонок и имеет 1000 строк.  
В ходе анализа данных было установлено, что в датасетах отсутствуют пропуски. Целевая переменная «is_fake» в датасете  train.tsv сбалансирована по классам 1  встречается 2879 и 0 встречается также 2879. Была определена длина текстовых сообщений и процент знаков препинания в них. Вымышленные новости имеют большую длину, чем реальные, но это различие не явно выраженное. Анализ процента знаков препинания нзначимых результатов не дал. Есть один повтор в строках 402 и 624, что маловероятно может сказаться на конечном результате, т.к. соответствующее данным строкам значение «is_fake» одинаковое. Скорее всего, это просто опечатка. Было построено облако слов, из которого сразу стало видно большое количетво «мусорных» слов.   
Была проведена предварительная обработка данных, в ходе которой была проведена проверка орфографии, очистка текста от «мусора» и приведение слов к стандартному виду, удаление пунктуации. Здесь применялось два подхода: лемматизация и стемминг. Леммитация, хоть и дольше по времени, но показала себя лучше. После обработки количество уникальных слов снизилось до 11778, что на 43% меньше.  
Для векторного представления текста использовались три подхода: Bag of words (BOW), TF-IDF,  и Bag of words (BOW) с биграммами (ngram_range=(1, 2)). На их основе строились 5 моделей: LogisticRegression, SGDClassifier, KNeighborsClassifier, RandomForestClassifier и XGBClassifier. По итогам сравнения, была выбрана модель  LogisticRegression, обученная на данных  Bag of words (BOW) с биграммами. Она показала точность 0 — 88% и 1 — 87%.  
Отбор фич с помощью LinearSVC положительных результатов не дал: точность упала на 3%, а время работы модели увеличилось. Подбор гиперпараметров по сетке GridSearchCV также не добавил существенного прироста. Только уменьшение времени работы модели с с 12,5с до 2,2с. Однако, при увеличении 'max_iter' до 10000, удалось немного улучшить результат, если судить по матрице ошибок.  
В ходе прогнозирования на тестовом датасете  test.tsv, были проведены те же процедуры по очистке, что и на тренировочном и использовалась лучшая модель с лучшими параметрами. Результатом предсказания стало отнесения 597 новостей к реальным (класс 0) и 403 к выдуманным (класс 1).  




